{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sft_aGpt56wg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # for using pandas daraframe\n",
        "import numpy as np # for som math operations\n",
        "from sklearn.preprocessing import StandardScaler # for standardizing the Data\n",
        "\n",
        "import matplotlib.pyplot as plt # for plotting\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "googledata1 = pd.read_csv('/content/Weekly_United_States_COVID-19_Cases_and_Deaths_by_State.csv')\n",
        "#googledata1['Date'] = pd.to_datetime(googledata1['Date'])\n",
        "df2 = googledata1\n",
        "cdc_d = df2[df2[\"state\"] == 'GA']\n",
        "\n",
        "cdc_d['Date'] = pd.to_datetime(cdc_d['start_date']) # tweets_df['Time'] = pd.to_datetime(tweets_df['Time'])\n",
        "\n",
        "# Getting week value\n",
        "\n",
        "cdc_d['Week'] = cdc_d['Date'].dt.isocalendar().week # Convert date to week and add a column Week.\n",
        "cdc_d['Year'] = cdc_d['Date'].dt.isocalendar().year # Convert date to year and add a column Year.\n",
        "\n",
        "cdc_d = cdc_d[((cdc_d[\"Year\"] == 2021))]\n",
        "\n",
        "#display(cdc_d)\n",
        "\n",
        "#dft = cdc_d[::-1]\n",
        "#display(dft)\n",
        "\n",
        "dfn1 = pd.DataFrame()\n",
        "l=[]\n",
        "\n",
        "for count, column in enumerate(cdc_d):    \n",
        "    # Select column contents by column\n",
        "    # name using [] operator\n",
        "    if(count>3)and(count<8):\n",
        "      columnSeriesObj = cdc_d[column]\n",
        "      columnSeriesObj[np.isnan(columnSeriesObj)] = 0\n",
        "      dfn1.insert(count-4, column, columnSeriesObj.tolist(), True)\n",
        "      l.append(columnSeriesObj.tolist())\n",
        "      #print('Column Name : ', column)\n",
        "      #print('Column Contents : ', columnSeriesObj.values)\n",
        "\n",
        "X1 = dfn1.values # getting all values as a matrix of dataframe \n",
        "sc = StandardScaler() # creating a StandardScaler object\n",
        "X_std1 = sc.fit_transform(X1) # standardizing the data"
      ],
      "metadata": {
        "id": "yRH_q8QKvgRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sym_2021 = pd.read_csv('/content/2021_sub_region_1_daily_2021_US_Georgia_daily_symptoms_dataset.csv')\n",
        "sym_2022 = pd.read_csv('/content/2022_sub_region_1_daily_2022_US_Georgia_daily_symptoms_dataset.csv')\n",
        "\n",
        "df3 = sym_2021.append(sym_2022) # Add both sets to make 2018-2019 set.\n",
        "\n",
        "# Converting values of Data column in datetime\n",
        "\n",
        "df3['Date'] = pd.to_datetime(df3['date']) # tweets_df['Time'] = pd.to_datetime(tweets_df['Time'])\n",
        "\n",
        "# Getting week value\n",
        "\n",
        "df3['Week'] = df3['Date'].dt.isocalendar().week # Convert date to week and add a column Week.\n",
        "df3['Year'] = df3['Date'].dt.isocalendar().year # Convert date to year and add a column Year.\n",
        "\n",
        "df3 = df3[(((df3[\"sub_region_1\"] == 'Georgia') & (df3[\"Year\"] == 2021)))]\n",
        "\n",
        "df3 = df3.resample('1W', on='Date').mean().reset_index()\n",
        "\n",
        "dfn = pd.DataFrame()\n",
        "for count, column in enumerate(df3):    \n",
        "    # Select column contents by column\n",
        "    # name using [] operator\n",
        "    if(count>2):\n",
        "      columnSeriesObj = df3[column]\n",
        "      columnSeriesObj[np.isnan(columnSeriesObj)] = 0\n",
        "      dfn.insert(count-3, column, columnSeriesObj.tolist(), True)\n",
        "      l.append(columnSeriesObj.tolist())\n",
        "      #print('Column Name : ', column)\n",
        "      #print('Column Contents : ', columnSeriesObj.values)\n",
        "\n",
        "X = dfn.values # getting all values as a matrix of dataframe \n",
        "sc = StandardScaler() # creating a StandardScaler object\n",
        "X_std = sc.fit_transform(X) # standardizing the data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0b06balvad6",
        "outputId": "31bd6bbc-b388-4c97-fb26-af4212ac319f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3249: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  if (await self.run_code(code, result,  async_=asy)):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Effect of enighbouring states on lead time\n"
      ],
      "metadata": {
        "id": "Q--gHwqo5-3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "googledata1 = pd.read_csv('/content/Weekly_United_States_COVID-19_Cases_and_Deaths_by_State.csv')\n",
        "#googledata1['Date'] = pd.to_datetime(googledata1['Date'])\n",
        "df2 = googledata1\n",
        "cdc_d = df2[df2[\"state\"] == 'AL']\n",
        "\n",
        "cdc_d['Date'] = pd.to_datetime(cdc_d['start_date']) # tweets_df['Time'] = pd.to_datetime(tweets_df['Time'])\n",
        "\n",
        "# Getting week value\n",
        "\n",
        "cdc_d['Week'] = cdc_d['Date'].dt.isocalendar().week # Convert date to week and add a column Week.\n",
        "cdc_d['Year'] = cdc_d['Date'].dt.isocalendar().year # Convert date to year and add a column Year.\n",
        "\n",
        "cdc_d = cdc_d[((cdc_d[\"Year\"] == 2021))]\n",
        "\n",
        "#display(cdc_d)\n",
        "\n",
        "#dft = cdc_d[::-1]\n",
        "#display(dft)\n",
        "\n",
        "dfn1 = pd.DataFrame()\n",
        "l=[]\n",
        "\n",
        "for count, column in enumerate(cdc_d):    \n",
        "    # Select column contents by column\n",
        "    # name using [] operator\n",
        "    if(count>3)and(count<8):\n",
        "      columnSeriesObj = cdc_d[column]\n",
        "      columnSeriesObj[np.isnan(columnSeriesObj)] = 0\n",
        "      dfn1.insert(count-4, column, columnSeriesObj.tolist(), True)\n",
        "      l.append(columnSeriesObj.tolist())\n",
        "      #print('Column Name : ', column)\n",
        "      #print('Column Contents : ', columnSeriesObj.values)\n",
        "\n",
        "X1 = dfn1.values # getting all values as a matrix of dataframe \n",
        "sc = StandardScaler() # creating a StandardScaler object\n",
        "X_std1 = sc.fit_transform(X1) # standardizing the data"
      ],
      "metadata": {
        "id": "TWpHBLUI6PHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sym_2021 = pd.read_csv('/content/2021_sub_region_1_daily_2021_US_Alabama_daily_symptoms_dataset.csv')\n",
        "sym_2022 = pd.read_csv('/content/2022_sub_region_1_daily_2022_US_Alabama_daily_symptoms_dataset (1).csv')\n",
        "\n",
        "df3 = sym_2021.append(sym_2022) # Add both sets to make 2018-2019 set.\n",
        "\n",
        "# Converting values of Data column in datetime\n",
        "\n",
        "df3['Date'] = pd.to_datetime(df3['date']) # tweets_df['Time'] = pd.to_datetime(tweets_df['Time'])\n",
        "\n",
        "# Getting week value\n",
        "\n",
        "df3['Week'] = df3['Date'].dt.isocalendar().week # Convert date to week and add a column Week.\n",
        "df3['Year'] = df3['Date'].dt.isocalendar().year # Convert date to year and add a column Year.\n",
        "\n",
        "df3 = df3[(((df3[\"sub_region_1\"] == 'Alabama') & (df3[\"Year\"] == 2021)))]\n",
        "\n",
        "df3 = df3.resample('1W', on='Date').mean().reset_index()\n",
        "\n",
        "dfn = pd.DataFrame()\n",
        "for count, column in enumerate(df3):    \n",
        "    # Select column contents by column\n",
        "    # name using [] operator\n",
        "    if(count>2):\n",
        "      columnSeriesObj = df3[column]\n",
        "      columnSeriesObj[np.isnan(columnSeriesObj)] = 0\n",
        "      dfn.insert(count-3, column, columnSeriesObj.tolist(), True)\n",
        "      l.append(columnSeriesObj.tolist())\n",
        "      #print('Column Name : ', column)\n",
        "      #print('Column Contents : ', columnSeriesObj.values)\n",
        "\n",
        "X = dfn.values # getting all values as a matrix of dataframe \n",
        "sc = StandardScaler() # creating a StandardScaler object\n",
        "X_std = sc.fit_transform(X) # standardizing the data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmAhU3fi6pnv",
        "outputId": "344fbb1a-853e-4ba3-a8f3-573ef85804e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3249: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  if (await self.run_code(code, result,  async_=asy)):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "    \n",
        "class Bit_map:\n",
        "\n",
        "    def __init__(self, reduced_size, inp_size, rng: np.random.RandomState = np.random.RandomState(0)):\n",
        "        self.reduced_size = reduced_size\n",
        "        self.inp_size = inp_size\n",
        "\n",
        "        # take random normal vectors for projection\n",
        "\n",
        "        self.normals = rng.randn(self.reduced_size, inp_size) \n",
        "        \n",
        "    def generate(self, inp_vector):\n",
        "\n",
        "        # self.normals.T = create delta normal vectors\n",
        "        # Take dot product of input vector with each of these normal vectors.\n",
        "        # If vector and normal on same side, then Binary = 1 else 0\n",
        "\n",
        "        binary = (np.dot(inp_vector, self.normals.T) > 0).astype('int')\n",
        "        return binary #''.join(bools.astype('str'))\n",
        "       \n",
        "ht = Bit_map(reduced_size=30, inp_size=52)"
      ],
      "metadata": {
        "id": "h5XfsBvK61Jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sp2 = ht.generate(X_std1[:,1])\n",
        "score = []\n",
        "h_l =[]\n",
        "\n",
        "for i in range(420):\n",
        "  h_p=[]\n",
        "  h_p.append(ht.generate(X_std[:,i]))\n",
        "  h_l.append(h_p)\n",
        "  \n",
        "for i in range(420):\n",
        "    sp1 = h_l[i] # Symptom data\n",
        "    a =[i for i, j in zip(sp1[0], sp2) if i == j];\n",
        "    score.append(len(a)) # How many bits are matching!\n",
        "\n",
        "top_k = sorted(range(len(score)), key=lambda i: score[i], reverse=True)[:15]\n",
        "top_k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tns_5SDq64Rf",
        "outputId": "eef40f87-d9c0-4ace-883c-5a0424d4315a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[73, 349, 74, 112, 210, 5, 54, 127, 132, 239, 273, 376, 18, 140, 175]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,c in enumerate(top_k): #for ele in enumerate(l1):\n",
        "  print(i,dfn.columns[c],score[c])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBBREfx06_15",
        "outputId": "81688163-095f-465d-cd9b-97e6dd94d5a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 symptom:Chest pain 25\n",
            "1 symptom:Shortness of breath 25\n",
            "2 symptom:Chills 24\n",
            "3 symptom:Dysgeusia 24\n",
            "4 symptom:Hypoxemia 24\n",
            "5 symptom:Ageusia 23\n",
            "6 symptom:Bradycardia 23\n",
            "7 symptom:Erectile dysfunction 23\n",
            "8 symptom:Eye pain 23\n",
            "9 symptom:Low-grade fever 23\n",
            "10 symptom:Night sweats 23\n",
            "11 symptom:Tachycardia 23\n",
            "12 symptom:Anosmia 22\n",
            "13 symptom:Fever 22\n",
            "14 symptom:Hemoptysis 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lead time"
      ],
      "metadata": {
        "id": "3NQiVU8y7J7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_std[:,175]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lw0Mi8gG9AFl",
        "outputId": "c44f4ea6-cc9b-4ebd-9f0a-fc68fe38f540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.07105917, -1.14504209,  1.28716044, -0.67731084,  0.44524418,\n",
              "       -0.20957958, -0.11603333, -0.67731084,  0.53879043, -0.39667208,\n",
              "       -1.7063196 , -1.00472272,  0.07105917, -0.39667208, -0.67731084,\n",
              "       -0.58376459,  0.44524418, -0.77085709, -1.42568085,  0.16460542,\n",
              "       -0.95794959, -1.23858834, -1.42568085, -1.14504209, -1.05149584,\n",
              "       -1.05149584, -1.05149584, -0.67731084, -0.20957958,  0.53879043,\n",
              "        0.81942918, -0.02248708,  0.91297543,  1.19361419,  1.47425294,\n",
              "       -0.20957958,  0.63233668, -0.49021834,  0.44524418, -0.39667208,\n",
              "        0.25815167, -0.20957958,  0.07105917, -0.77085709,  0.25815167,\n",
              "        1.47425294,  1.38070669,  1.75489169,  0.44524418,  0.72588293,\n",
              "        1.94198419,  3.34517796])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corr_t =[]\n",
        "valuesi = []\n",
        "sim = [73, 349, 74, 112, 210, 5, 54, 127, 132, 239, 273, 376, 18, 140, 175] # Coluns from top correlated data.\n",
        "zp = []\n",
        "\n",
        "\n",
        "for j in sim:\n",
        "\n",
        "  a = X_std1[:,0]\n",
        "  b = X_std[:,j]\n",
        "\n",
        "  colin = [] \n",
        "  z = 52\n",
        "  for t in range(z): # vary t' from 1 to 34\n",
        "\n",
        "    if(t>1) and (t<z+1):\n",
        "      symp_a = b[:(z+1-(t))]\n",
        "      ili_a  = a[t-1:z+1]\n",
        "      res = stats.pearsonr(ili_a, np.nan_to_num(symp_a))\n",
        "      colin.append(res) # Append all possible correlation for varying t\n",
        "    \n",
        "  arr1 = np.array(colin)\n",
        "  zil = arr1.argmax(axis=0)\n",
        "  zp.append(zil[0])\n",
        "  \n",
        "  corr_t.append(colin)\n",
        "\n",
        "for count,k in enumerate(zp):\n",
        "  print(count,k)"
      ],
      "metadata": {
        "id": "Mm6FOAZ47CNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for count,k in enumerate(zp):\n",
        "  print(count,k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jI_OoLox7gkc",
        "outputId": "6bd97986-160d-4ca6-ab21-cb65be8b012f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 49\n",
            "1 12\n",
            "2 0\n",
            "3 13\n",
            "4 9\n",
            "5 10\n",
            "6 47\n",
            "7 49\n",
            "8 48\n",
            "9 12\n",
            "10 47\n",
            "11 49\n",
            "12 10\n",
            "13 13\n",
            "14 48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5dWDJCaa7ikC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Georgia**"
      ],
      "metadata": {
        "id": "M2xpY_g59jyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sym_2021 = pd.read_csv('/content/2021_sub_region_1_daily_2021_US_Georgia_daily_symptoms_dataset.csv')\n",
        "sym_2022 = pd.read_csv('/content/2022_sub_region_1_daily_2022_US_Georgia_daily_symptoms_dataset.csv')\n",
        "\n",
        "df3 = sym_2021.append(sym_2022) # Add both sets to make 2018-2019 set.\n",
        "\n",
        "# Converting values of Data column in datetime\n",
        "\n",
        "df3['Date'] = pd.to_datetime(df3['date']) # tweets_df['Time'] = pd.to_datetime(tweets_df['Time'])\n",
        "\n",
        "# Getting week value\n",
        "\n",
        "df3['Week'] = df3['Date'].dt.isocalendar().week # Convert date to week and add a column Week.\n",
        "df3['Year'] = df3['Date'].dt.isocalendar().year # Convert date to year and add a column Year.\n",
        "\n",
        "df3 = df3[(((df3[\"sub_region_1\"] == 'Georgia') & (df3[\"Year\"] == 2021)))]\n",
        "\n",
        "df3 = df3.resample('1W', on='Date').mean().reset_index()\n",
        "\n",
        "dfn = pd.DataFrame()\n",
        "for count, column in enumerate(df3):    \n",
        "    # Select column contents by column\n",
        "    # name using [] operator\n",
        "    if(count>2):\n",
        "      columnSeriesObj = df3[column]\n",
        "      columnSeriesObj[np.isnan(columnSeriesObj)] = 0\n",
        "      dfn.insert(count-3, column, columnSeriesObj.tolist(), True)\n",
        "      l.append(columnSeriesObj.tolist())\n",
        "      #print('Column Name : ', column)\n",
        "      #print('Column Contents : ', columnSeriesObj.values)\n",
        "\n",
        "X = dfn.values # getting all values as a matrix of dataframe \n",
        "sc = StandardScaler() # creating a StandardScaler object\n",
        "X_std = sc.fit_transform(X) # standardizing the data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtSa52iH9ljq",
        "outputId": "dea779e3-ef43-4b7d-a9c6-e2f9f4258c0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3249: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  if (await self.run_code(code, result,  async_=asy)):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corr_t =[]\n",
        "valuesi = []\n",
        "sim = [73, 349, 74, 112, 210, 5, 54, 127, 132, 239, 273, 376, 18, 140, 175] # Coluns from top correlated data.\n",
        "zp = []\n",
        "\n",
        "for j in sim:\n",
        "\n",
        "  a = X_std1[:,0]\n",
        "  b = X_std[:,j]\n",
        "\n",
        "  colin = [] \n",
        "  z = 52\n",
        "  for t in range(z): # vary t' from 1 to 34\n",
        "\n",
        "    if(t>1) and (t<z+1):\n",
        "      symp_a = b[:(z+1-(t))]\n",
        "      ili_a  = a[t-1:z+1]\n",
        "      res = stats.pearsonr(ili_a, np.nan_to_num(symp_a))\n",
        "      colin.append(res) # Append all possible correlation for varying t\n",
        "    \n",
        "  arr1 = np.array(colin)\n",
        "  zil = arr1.argmax(axis=0)\n",
        "  zp.append(zil[0])\n",
        "  \n",
        "  corr_t.append(colin)"
      ],
      "metadata": {
        "id": "IW3dtNfh9qJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for count,k in enumerate(zp):\n",
        "  print(count,k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oNcnhuz95xq",
        "outputId": "fb9d9069-6682-4c36-b561-398d4f0786d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 49\n",
            "1 47\n",
            "2 0\n",
            "3 9\n",
            "4 7\n",
            "5 10\n",
            "6 49\n",
            "7 49\n",
            "8 11\n",
            "9 0\n",
            "10 47\n",
            "11 49\n",
            "12 5\n",
            "13 5\n",
            "14 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "# This is formatted as code\n",
        "\n",
        "0 symptom:Chest pain 25\n",
        "1 symptom:Shortness of breath 25\n",
        "2 symptom:Chills 24\n",
        "3 symptom:Dysgeusia 24\n",
        "4 symptom:Hypoxemia 24\n",
        "5 symptom:Ageusia 23\n",
        "6 symptom:Bradycardia 23\n",
        "7 symptom:Erectile dysfunction 23\n",
        "8 symptom:Eye pain 23\n",
        "9 symptom:Low-grade fever 23\n",
        "10 symptom:Night sweats 23\n",
        "11 symptom:Tachycardia 23\n",
        "12 symptom:Anosmia 22\n",
        "13 symptom:Fever 22\n",
        "14 symptom:Hemoptysis 22\n",
        "```"
      ],
      "metadata": {
        "id": "qnVphdDh-Rdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "0 49\n",
        "1 12\n",
        "2 0\n",
        "3 13\n",
        "4 9\n",
        "5 10\n",
        "6 47\n",
        "7 49\n",
        "8 48\n",
        "9 12\n",
        "10 47\n",
        "11 49\n",
        "12 10\n",
        "13 13\n",
        "14 48"
      ],
      "metadata": {
        "id": "oHzD-Gd896wN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q2djIw-7-iJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**South Carolina**"
      ],
      "metadata": {
        "id": "LxLxUdTe-idk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "googledata1 = pd.read_csv('/content/Weekly_United_States_COVID-19_Cases_and_Deaths_by_State.csv')\n",
        "#googledata1['Date'] = pd.to_datetime(googledata1['Date'])\n",
        "df2 = googledata1\n",
        "cdc_d = df2[df2[\"state\"] == 'SC']\n",
        "\n",
        "cdc_d['Date'] = pd.to_datetime(cdc_d['start_date']) # tweets_df['Time'] = pd.to_datetime(tweets_df['Time'])\n",
        "\n",
        "# Getting week value\n",
        "\n",
        "cdc_d['Week'] = cdc_d['Date'].dt.isocalendar().week # Convert date to week and add a column Week.\n",
        "cdc_d['Year'] = cdc_d['Date'].dt.isocalendar().year # Convert date to year and add a column Year.\n",
        "\n",
        "cdc_d = cdc_d[((cdc_d[\"Year\"] == 2021))]\n",
        "\n",
        "#display(cdc_d)\n",
        "\n",
        "#dft = cdc_d[::-1]\n",
        "#display(dft)\n",
        "\n",
        "dfn1 = pd.DataFrame()\n",
        "l=[]\n",
        "\n",
        "for count, column in enumerate(cdc_d):    \n",
        "    # Select column contents by column\n",
        "    # name using [] operator\n",
        "    if(count>3)and(count<8):\n",
        "      columnSeriesObj = cdc_d[column]\n",
        "      columnSeriesObj[np.isnan(columnSeriesObj)] = 0\n",
        "      dfn1.insert(count-4, column, columnSeriesObj.tolist(), True)\n",
        "      l.append(columnSeriesObj.tolist())\n",
        "      #print('Column Name : ', column)\n",
        "      #print('Column Contents : ', columnSeriesObj.values)\n",
        "\n",
        "X1 = dfn1.values # getting all values as a matrix of dataframe \n",
        "sc = StandardScaler() # creating a StandardScaler object\n",
        "X_std1 = sc.fit_transform(X1) # standardizing the data\n",
        "\n",
        "\n",
        "sym_2021 = pd.read_csv('/content/2021_sub_region_1_daily_2021_US_South_Carolina_daily_symptoms_dataset.csv')\n",
        "sym_2022 = pd.read_csv('/content/2022_sub_region_1_daily_2022_US_South_Carolina_daily_symptoms_dataset.csv')\n",
        "\n",
        "df3 = sym_2021.append(sym_2022) # Add both sets to make 2018-2019 set.\n",
        "\n",
        "# Converting values of Data column in datetime\n",
        "\n",
        "df3['Date'] = pd.to_datetime(df3['date']) # tweets_df['Time'] = pd.to_datetime(tweets_df['Time'])\n",
        "\n",
        "# Getting week value\n",
        "\n",
        "df3['Week'] = df3['Date'].dt.isocalendar().week # Convert date to week and add a column Week.\n",
        "df3['Year'] = df3['Date'].dt.isocalendar().year # Convert date to year and add a column Year.\n",
        "\n",
        "df3 = df3[(((df3[\"sub_region_1\"] == 'South Carolina') & (df3[\"Year\"] == 2021)))]\n",
        "\n",
        "df3 = df3.resample('1W', on='Date').mean().reset_index()\n",
        "\n",
        "dfn = pd.DataFrame()\n",
        "for count, column in enumerate(df3):    \n",
        "    # Select column contents by column\n",
        "    # name using [] operator\n",
        "    if(count>2):\n",
        "      columnSeriesObj = df3[column]\n",
        "      columnSeriesObj[np.isnan(columnSeriesObj)] = 0\n",
        "      dfn.insert(count-3, column, columnSeriesObj.tolist(), True)\n",
        "      l.append(columnSeriesObj.tolist())\n",
        "      #print('Column Name : ', column)\n",
        "      #print('Column Contents : ', columnSeriesObj.values)\n",
        "\n",
        "X = dfn.values # getting all values as a matrix of dataframe \n",
        "sc = StandardScaler() # creating a StandardScaler object\n",
        "X_std = sc.fit_transform(X) # standardizing the data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcrzFHZ8-kHs",
        "outputId": "30845e97-8635-495f-8e29-319d3df1b5de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:63: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3249: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  if (await self.run_code(code, result,  async_=asy)):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sp2 = ht.generate(X_std1[:,1])\n",
        "score = []\n",
        "h_l =[]\n",
        "\n",
        "for i in range(420):\n",
        "  h_p=[]\n",
        "  h_p.append(ht.generate(X_std[:,i]))\n",
        "  h_l.append(h_p)\n",
        "  \n",
        "for i in range(420):\n",
        "    sp1 = h_l[i] # Symptom data\n",
        "    a =[i for i, j in zip(sp1[0], sp2) if i == j];\n",
        "    score.append(len(a)) # How many bits are matching!\n",
        "\n",
        "top_k = sorted(range(len(score)), key=lambda i: score[i], reverse=True)[:15]\n",
        "top_k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIzOfdYe-xB-",
        "outputId": "f4b15136-3729-42c2-9505-80d698c0c723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 210, 349, 18, 54, 127, 376, 73, 165, 167, 249, 319, 112, 164, 211]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,c in enumerate(top_k): #for ele in enumerate(l1):\n",
        "  print(i,dfn.columns[c],score[c])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8dLE61F-zk5",
        "outputId": "e7887cc1-cfa5-484a-c2fa-664d4f0219f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 symptom:Chest pain 25\n",
            "1 symptom:Shortness of breath 25\n",
            "2 symptom:Chills 24\n",
            "3 symptom:Dysgeusia 24\n",
            "4 symptom:Hypoxemia 24\n",
            "5 symptom:Ageusia 23\n",
            "6 symptom:Bradycardia 23\n",
            "7 symptom:Erectile dysfunction 23\n",
            "8 symptom:Eye pain 23\n",
            "9 symptom:Low-grade fever 23\n",
            "10 symptom:Night sweats 23\n",
            "11 symptom:Tachycardia 23\n",
            "12 symptom:Anosmia 22\n",
            "13 symptom:Fever 22\n",
            "14 symptom:Hemoptysis 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corr_t =[]\n",
        "valuesi = []\n",
        "sim = [5, 210, 349, 18, 54, 127, 376, 73, 165, 167, 249, 319, 112, 164, 211] # Coluns from top correlated data.\n",
        "zp = []\n",
        "\n",
        "for j in sim:\n",
        "\n",
        "  a = X_std1[:,0]\n",
        "  b = X_std[:,j]\n",
        "\n",
        "  colin = [] \n",
        "  z = 52\n",
        "  for t in range(z): # vary t' from 1 to 34\n",
        "\n",
        "    if(t>1) and (t<z+1):\n",
        "      symp_a = b[:(z+1-(t))]\n",
        "      ili_a  = a[t-1:z+1]\n",
        "      res = stats.pearsonr(ili_a, np.nan_to_num(symp_a))\n",
        "      colin.append(res) # Append all possible correlation for varying t\n",
        "    \n",
        "  arr1 = np.array(colin)\n",
        "  zil = arr1.argmax(axis=0)\n",
        "  zp.append(zil[0])\n",
        "  \n",
        "  corr_t.append(colin)\n",
        "\n",
        "for count,k in enumerate(zp):\n",
        "  print(count,k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0q14Y_q-33o",
        "outputId": "50828825-3f3b-4d67-f0ed-8ca3b2faf276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 10\n",
            "1 8\n",
            "2 49\n",
            "3 4\n",
            "4 49\n",
            "5 49\n",
            "6 49\n",
            "7 47\n",
            "8 44\n",
            "9 13\n",
            "10 49\n",
            "11 47\n",
            "12 10\n",
            "13 48\n",
            "14 49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corr_t =[]\n",
        "valuesi = []\n",
        "sim = [5, 210, 349, 18, 54, 127, 376, 73, 165, 167, 249, 319, 112, 164, 211] # Coluns from top correlated data.\n",
        "zp = []\n",
        "\n",
        "for j in sim:\n",
        "\n",
        "  a = X_std1[:,0]\n",
        "  b = X_std[:,j]\n",
        "\n",
        "  colin = [] \n",
        "  z = 52\n",
        "  for t in range(z): # vary t' from 1 to 34\n",
        "\n",
        "    if(t>1) and (t<z+1):\n",
        "      symp_a = b[:(z+1-(t))]\n",
        "      ili_a  = a[t-1:z+1]\n",
        "      res = stats.pearsonr(ili_a, np.nan_to_num(symp_a))\n",
        "      colin.append(res) # Append all possible correlation for varying t\n",
        "    \n",
        "  arr1 = np.array(colin)\n",
        "  zil = arr1.argmax(axis=0)\n",
        "  zp.append(zil[0])\n",
        "  \n",
        "  corr_t.append(colin)"
      ],
      "metadata": {
        "id": "0aSSFcAYC48H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for count,k in enumerate(zp):\n",
        "  print(count,k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM1aWMHRDyc0",
        "outputId": "53d1fe58-96c2-495a-82f0-b6c3580709ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 11\n",
            "1 8\n",
            "2 47\n",
            "3 10\n",
            "4 49\n",
            "5 49\n",
            "6 49\n",
            "7 49\n",
            "8 44\n",
            "9 15\n",
            "10 49\n",
            "11 49\n",
            "12 11\n",
            "13 49\n",
            "14 49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "0 symptom:Ageusia 27\n",
        "1 symptom:Hypoxemia 27\n",
        "2 symptom:Shortness of breath 27\n",
        "3 symptom:Anosmia 26\n",
        "4 symptom:Bradycardia 26\n",
        "5 symptom:Erectile dysfunction 26\n",
        "6 symptom:Tachycardia 26\n",
        "7 symptom:Chest pain 25\n",
        "8 symptom:Halitosis 25\n",
        "9 symptom:Headache 25\n",
        "10 symptom:Middle back pain 25\n",
        "11 symptom:Pruritus ani 25\n",
        "12 symptom:Dysgeusia 24\n",
        "13 symptom:Hair loss 24\n",
        "14 symptom:Hypoxia 24\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "_r1-kWajD6oT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "0 10\n",
        "1 8\n",
        "2 49\n",
        "3 4\n",
        "4 49\n",
        "5 49\n",
        "6 49\n",
        "7 47\n",
        "8 44\n",
        "9 13\n",
        "10 49\n",
        "11 47\n",
        "12 10\n",
        "13 48\n",
        "14 49"
      ],
      "metadata": {
        "id": "Diy9Okd0D23s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Alabama**"
      ],
      "metadata": {
        "id": "zjz_bT1ssjrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "googledata1 = pd.read_csv('/content/Weekly_United_States_COVID-19_Cases_and_Deaths_by_State.csv')\n",
        "#googledata1['Date'] = pd.to_datetime(googledata1['Date'])\n",
        "df2 = googledata1\n",
        "cdc_d = df2[df2[\"state\"] == 'AL']\n",
        "\n",
        "cdc_d['Date'] = pd.to_datetime(cdc_d['start_date']) # tweets_df['Time'] = pd.to_datetime(tweets_df['Time'])\n",
        "\n",
        "# Getting week value\n",
        "\n",
        "cdc_d['Week'] = cdc_d['Date'].dt.isocalendar().week # Convert date to week and add a column Week.\n",
        "cdc_d['Year'] = cdc_d['Date'].dt.isocalendar().year # Convert date to year and add a column Year.\n",
        "\n",
        "cdc_d = cdc_d[((cdc_d[\"Year\"] == 2021))]\n",
        "\n",
        "#display(cdc_d)\n",
        "\n",
        "#dft = cdc_d[::-1]\n",
        "#display(dft)\n",
        "\n",
        "dfn1 = pd.DataFrame()\n",
        "l=[]\n",
        "\n",
        "for count, column in enumerate(cdc_d):    \n",
        "    # Select column contents by column\n",
        "    # name using [] operator\n",
        "    if(count>3)and(count<8):\n",
        "      columnSeriesObj = cdc_d[column]\n",
        "      columnSeriesObj[np.isnan(columnSeriesObj)] = 0\n",
        "      dfn1.insert(count-4, column, columnSeriesObj.tolist(), True)\n",
        "      l.append(columnSeriesObj.tolist())\n",
        "      #print('Column Name : ', column)\n",
        "      #print('Column Contents : ', columnSeriesObj.values)\n",
        "\n",
        "X1 = dfn1.values # getting all values as a matrix of dataframe \n",
        "sc = StandardScaler() # creating a StandardScaler object\n",
        "X_std1 = sc.fit_transform(X1) # standardizing the data\n",
        "\n",
        "\n",
        "sym_2021 = pd.read_csv('/content/2021_sub_region_1_daily_2021_US_Alabama_daily_symptoms_dataset.csv')\n",
        "sym_2022 = pd.read_csv('/content/2022_sub_region_1_daily_2022_US_Alabama_daily_symptoms_dataset (1).csv')\n",
        "\n",
        "df3 = sym_2021.append(sym_2022) # Add both sets to make 2018-2019 set.\n",
        "\n",
        "# Converting values of Data column in datetime\n",
        "\n",
        "df3['Date'] = pd.to_datetime(df3['date']) # tweets_df['Time'] = pd.to_datetime(tweets_df['Time'])\n",
        "\n",
        "# Getting week value\n",
        "\n",
        "df3['Week'] = df3['Date'].dt.isocalendar().week # Convert date to week and add a column Week.\n",
        "df3['Year'] = df3['Date'].dt.isocalendar().year # Convert date to year and add a column Year.\n",
        "\n",
        "df3 = df3[(((df3[\"sub_region_1\"] == 'Alabama') & (df3[\"Year\"] == 2021)))]\n",
        "\n",
        "df3 = df3.resample('1W', on='Date').mean().reset_index()\n",
        "\n",
        "dfn = pd.DataFrame()\n",
        "for count, column in enumerate(df3):    \n",
        "    # Select column contents by column\n",
        "    # name using [] operator\n",
        "    if(count>2):\n",
        "      columnSeriesObj = df3[column]\n",
        "      columnSeriesObj[np.isnan(columnSeriesObj)] = 0\n",
        "      dfn.insert(count-3, column, columnSeriesObj.tolist(), True)\n",
        "      l.append(columnSeriesObj.tolist())\n",
        "      #print('Column Name : ', column)\n",
        "      #print('Column Contents : ', columnSeriesObj.values)\n",
        "\n",
        "X = dfn.values # getting all values as a matrix of dataframe \n",
        "sc = StandardScaler() # creating a StandardScaler object\n",
        "X_std = sc.fit_transform(X) # standardizing the data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgfBPxbdsmVT",
        "outputId": "2d255684-4568-4878-bada-305d9a99c108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:63: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3249: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  if (await self.run_code(code, result,  async_=asy)):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sp2 = ht.generate(X_std1[:,1])\n",
        "score = []\n",
        "h_l =[]\n",
        "\n",
        "for i in range(420):\n",
        "  h_p=[]\n",
        "  h_p.append(ht.generate(X_std[:,i]))\n",
        "  h_l.append(h_p)\n",
        "  \n",
        "for i in range(420):\n",
        "    sp1 = h_l[i] # Symptom data\n",
        "    a =[i for i, j in zip(sp1[0], sp2) if i == j];\n",
        "    score.append(len(a)) # How many bits are matching!\n",
        "\n",
        "top_k = sorted(range(len(score)), key=lambda i: score[i], reverse=True)[:15]\n",
        "top_k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCnk5ZAOsr9E",
        "outputId": "0fb3d1d4-8d8e-41f2-d447-643b557c1350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[73, 349, 74, 112, 210, 5, 54, 127, 132, 239, 273, 376, 18, 140, 175]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,c in enumerate(top_k): #for ele in enumerate(l1):\n",
        "  print(i,dfn.columns[c],score[c])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFEOBFestiUc",
        "outputId": "37c2ec98-410e-4286-f949-242b4576e59b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 symptom:Chest pain 25\n",
            "1 symptom:Shortness of breath 25\n",
            "2 symptom:Chills 24\n",
            "3 symptom:Dysgeusia 24\n",
            "4 symptom:Hypoxemia 24\n",
            "5 symptom:Ageusia 23\n",
            "6 symptom:Bradycardia 23\n",
            "7 symptom:Erectile dysfunction 23\n",
            "8 symptom:Eye pain 23\n",
            "9 symptom:Low-grade fever 23\n",
            "10 symptom:Night sweats 23\n",
            "11 symptom:Tachycardia 23\n",
            "12 symptom:Anosmia 22\n",
            "13 symptom:Fever 22\n",
            "14 symptom:Hemoptysis 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corr_t =[]\n",
        "valuesi = []\n",
        "sim = [73, 349, 74, 112, 210, 5, 54, 127, 132, 239, 273, 376, 18, 140, 175] # Coluns from top correlated data.\n",
        "zp = []\n",
        "\n",
        "for j in sim:\n",
        "\n",
        "  a = X_std1[:,0]\n",
        "  b = X_std[:,j]\n",
        "\n",
        "  colin = [] \n",
        "  z = 52\n",
        "  for t in range(z): # vary t' from 1 to 34\n",
        "\n",
        "    if(t>1) and (t<z+1):\n",
        "      symp_a = b[:(z+1-(t))]\n",
        "      ili_a  = a[t-1:z+1]\n",
        "      res = stats.pearsonr(ili_a, np.nan_to_num(symp_a))\n",
        "      colin.append(res) # Append all possible correlation for varying t\n",
        "    \n",
        "  arr1 = np.array(colin)\n",
        "  zil = arr1.argmax(axis=0)\n",
        "  zp.append(zil[0])\n",
        "  \n",
        "  corr_t.append(colin)\n",
        "\n",
        "for count,k in enumerate(zp):\n",
        "  print(count,k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZ03Ogx4sv9E",
        "outputId": "94de04f3-0575-49ef-b9da-04acce8d305c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 49\n",
            "1 12\n",
            "2 0\n",
            "3 13\n",
            "4 9\n",
            "5 10\n",
            "6 47\n",
            "7 49\n",
            "8 48\n",
            "9 12\n",
            "10 47\n",
            "11 49\n",
            "12 10\n",
            "13 13\n",
            "14 48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sym_2021 = pd.read_csv('/content/2021_sub_region_1_daily_2021_US_Georgia_daily_symptoms_dataset.csv')\n",
        "sym_2022 = pd.read_csv('/content/2022_sub_region_1_daily_2022_US_Georgia_daily_symptoms_dataset.csv')\n",
        "\n",
        "df3 = sym_2021.append(sym_2022) # Add both sets to make 2018-2019 set.\n",
        "\n",
        "# Converting values of Data column in datetime\n",
        "\n",
        "df3['Date'] = pd.to_datetime(df3['date']) # tweets_df['Time'] = pd.to_datetime(tweets_df['Time'])\n",
        "\n",
        "# Getting week value\n",
        "\n",
        "df3['Week'] = df3['Date'].dt.isocalendar().week # Convert date to week and add a column Week.\n",
        "df3['Year'] = df3['Date'].dt.isocalendar().year # Convert date to year and add a column Year.\n",
        "\n",
        "df3 = df3[(((df3[\"sub_region_1\"] == 'Georgia') & (df3[\"Year\"] == 2021)))]\n",
        "\n",
        "df3 = df3.resample('1W', on='Date').mean().reset_index()\n",
        "\n",
        "dfn = pd.DataFrame()\n",
        "for count, column in enumerate(df3):    \n",
        "    # Select column contents by column\n",
        "    # name using [] operator\n",
        "    if(count>2):\n",
        "      columnSeriesObj = df3[column]\n",
        "      columnSeriesObj[np.isnan(columnSeriesObj)] = 0\n",
        "      dfn.insert(count-3, column, columnSeriesObj.tolist(), True)\n",
        "      l.append(columnSeriesObj.tolist())\n",
        "      #print('Column Name : ', column)\n",
        "      #print('Column Contents : ', columnSeriesObj.values)\n",
        "\n",
        "X = dfn.values # getting all values as a matrix of dataframe \n",
        "sc = StandardScaler() # creating a StandardScaler object\n",
        "X_std = sc.fit_transform(X) # standardizing the data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DfcYBdDtXGa",
        "outputId": "afb46f7a-02b5-4c33-8394-0079eb45bfeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3249: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  if (await self.run_code(code, result,  async_=asy)):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corr_t =[]\n",
        "valuesi = []\n",
        "sim = [63, 349, 73, 158, 249, 273, 18, 23, 127, 140, 167, 112, 132, 215, 250] # Coluns from top correlated data from georgia cases data.\n",
        "zp = []\n",
        "\n",
        "for j in sim:\n",
        "\n",
        "  a = X_std1[:,0]\n",
        "  b = X_std[:,j]\n",
        "\n",
        "  colin = [] \n",
        "  z = 52\n",
        "  for t in range(z): # vary t' from 1 to 34\n",
        "\n",
        "    if(t>1) and (t<z+1):\n",
        "      symp_a = b[:(z+1-(t))]\n",
        "      ili_a  = a[t-1:z+1]\n",
        "      res = stats.pearsonr(ili_a, np.nan_to_num(symp_a))\n",
        "      colin.append(res) # Append all possible correlation for varying t\n",
        "    \n",
        "  arr1 = np.array(colin)\n",
        "  zil = arr1.argmax(axis=0)\n",
        "  zp.append(zil[0])\n",
        "  \n",
        "  corr_t.append(colin)"
      ],
      "metadata": {
        "id": "KuAhQQUdtrss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for count,k in enumerate(zp):\n",
        "  print(count,k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmGiwjs2uH2w",
        "outputId": "6e737c12-6399-4097-cca1-f16a6f140172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 47\n",
            "1 47\n",
            "2 49\n",
            "3 49\n",
            "4 49\n",
            "5 47\n",
            "6 5\n",
            "7 47\n",
            "8 49\n",
            "9 5\n",
            "10 44\n",
            "11 9\n",
            "12 11\n",
            "13 49\n",
            "14 44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "0 49\n",
        "1 12\n",
        "2 0\n",
        "3 13\n",
        "4 9\n",
        "5 10\n",
        "6 47\n",
        "7 49\n",
        "8 48\n",
        "9 12\n",
        "10 47\n",
        "11 49\n",
        "12 10\n",
        "13 13\n",
        "14 48"
      ],
      "metadata": {
        "id": "5eOEYqvEuLL-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}